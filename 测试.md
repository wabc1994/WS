# 测试
1. 测试环境Linux centos
2. 测试工具 webbench 网页测压工具
3. 关闭TCP Nagle算法（减少小包的发送数量，提供）
4. 分别测试长连接和短连接之间的两种情况
5. 观察指标，就是显示给我们的信息:Page/min:指输出的页数/分、bytes/sec: 是指比特/秒


# 为何要关闭tcp_nodelay
现在让我们假设某个应用程序发出了一个请求，希望发送小块数据，比如sns游戏中的点击确定按钮。我们可以选择立即发送数据或者等待产生更多的数据然后再一次发送两种策略。如果我们马上发送数据，那么交互性的以及客户/服务器型的应用程序将极大地受益。例如，当我们正在发送一个较短的请求并且等候较大的响应时，相关过载与传输的数据总量相比就会比较低，而且，如果请求立即发出那么响应时间也会快一些。以上操作可以通过设置套接字的TCP_NODELAY选项来完成，这样就禁用了Nagle算法，在nginx中设置tcp_nodelay on,注意放在http标签里。
   
   另外一种情况则需要我们等到数据量达到最大时才通过网络一次发送全部数据，这种数据传输方式有益于大量数据的通信性能，典型的应用就是文件服务器。应用Nagle算法在这种情况下就会产生问题。但是，如果你正在发送大量数据，你可以设置TCP_CORK选项禁用Nagle化，其方式正好同TCP_NODELAY相反（TCP_CORK 和 TCP_NODELAY 是互相排斥的）。下面就让我们仔细分析下其工作原理。 
      
 >Nagle算法用于对缓冲区内的一定数量的消息进行自动连接。该处理过程(称为Nagling)，通过减少必须发送的封包的数量，提高了网络应用 程序系统的效率. 但是会带来一定的延迟，所以我们得禁止掉他
 
# 修改Linux tcp/ip 协议tcp相关的参数


[大并发下listen的连接完成对列backlog太小导致客户超时，服务器效率低下 ](https://blog.csdn.net/lizhi200404520/article/details/6981272)

[How TCP backlog works in Linux](http://veithen.io/2014/01/01/how-tcp-backlog-works-in-linux.html)

## man listen()
 // 服务器进行监听的 全连接队列情况
 
 ```java
 
 int socket_bind_listen
  
  // 虽然设置为2048 实质上最大只能为128个
 
    if(listen(listen_fd, 2048) == -1)
        return -1;
 ```
 
 
-  cat /proc/sys/net/ipv4/tcp_max_syn_backlog 1024 这是默认情况下值，这是半连接队列大小
-  net.ipv4.tcp_max_syn_backlog = 8192
表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。
-  全连接队列的默认大小是 cat /proc/sys/net/core/somaxconn 128


 
 **accept queue满了之后** 
 >listen 第二个backlog参数设置太小，原来上面这个服务器代码listen指定的backlog连接完成队列参数太小，只有32，导致高并发的时候，服务器的连接完成队列在极短的时间内被填满了，而accept的处理速度跟不上队列填满的速度，导致队列始终是满的，然后就不理会客户的其他连接请求，导致了客户connect超时，并且处理效率低下。
而线程池的backlog有1024，不过受限于内核参数的默认值最大128，所以线程池这个的backlog实际是128（见man listen），再加上300个线程，每个线程独自accpet，所以能很快从完成队列中取得连接，客户的connect也不会超时了，如果把线程数改为1个，客户连接也会超时。
 
 

***满了之后如果开启了tcp_syncookies机制***

当 SYN queue 满了，系统还在不断的收到 SYN 包时，系统怎么处理的？系统会根据内核参数 net.ipv4.tcp_syncookies 的值来处理请求。tcp_syncookies 是用来防止 SYN flood 攻击，其原理是在半连接队列满时，SYN cookies 并不丢弃 SYN 请求，而是将源目的 IP、源目的端口号、接收到的 client 端初始序列号以及其他一些安全数值等信息进行 hash 运算，并加密后得到 server 端的初始序列号，称之为 cookie。server 端在发送初始序列号为 cookie 的 SYN+ACK 包后，会将分配的连接请求块释放。如果接收到 client 端的 ACK 包，server 端将 client 端的 ACK 序列号减 1 得到的值，与上述要素 hash 运算得到的值比较，如果相等，直接完成三次握手，构建新的连接。SYN cookies 机制的核心就是避免攻击造成的大量构造无用的连接请求块，导致内存耗尽，而无法处理正常的连接请求。

当 syn queue 满了，在 Server 端没有开启 syncookies 的时候，即 syncookies=0，server 端会丢弃新来的 SYN 包，而 client 端在多次重发 SYN 包得不到响应而返回 connection time out 错误。但是，当 Server 端开启了 syncookies, 即 syncookies=1，那么 SYN queue 就在逻辑上的没有最大值了，而是忽略内核参数 net.ipv4.tcp_max_syn_backlog 设置的值。Client 端在多次重发 SYN 包得不到响应而返回 connection time out 错误。


- tcp\_max\_syn\_backlog
- tcp\_\synack\_retries 服务器在没有收到客户端第三次ack的报文
- tcp\_abort\_on\_overflow 全连接队列满了之后，服务器发送rst 给客户端的ack 第二次确认报文

[SYN Cookie的原理和实现 ](https://www.cnblogs.com/i0ject/p/3869231.html)


 
大并发下listen的连接完成对列backlog太小导致客户超时，服务器效率低下，因为我把backlog 参数设置为最大值2048, 默认是128


## SYN flood攻击

半连接之后服务器端就为客户端分配数据结构、内存等资源，如果一只耳没收到客户端的ack，这些资源就一直不释放的，导致服务器资源耗尽，不能正常对外提供服务
tcp\_syn\_cookies=1 开启防御

- 注意，即使开启该机制并不意味着所有的连接都是用 SYN cookies 机制来完成连接的建立，只有在 SYN queue 已满的情况下才会触发 SYN cookies 机制。

- 由于 SYN cookies 机制严重违背 TCP 协议，不允许使用 TCP 扩展，可能对某些服务造成严重的性能影响（如 SMTP 转发），对于防御 SYN flood 攻击的确有效。对于没有收到攻击的高负载服务器，不要开启此选项，可以通过修改 

## **全连接队列的大小确定**

全连接队列的大小min(backlog,somaxconn)，SOMAXCONN 默认是128 ，backlog 是用户程序调用listen()指定，全连接队列和半连接队列是由用户应用程序和Linux系统内核来决定的

net.core.synconnm

**半连接队列的大小**

max(tcp_max_syn_backlog,64） 其中Linux 内核当中tcp_max_syn_backlog 是1024 ，处于SYN_SEND和SYN_RECV的都是半连接状态的，半连接队列是由系统参数和Linux tcp/ip协议栈来解决的


# Linux tcp/ip协议栈参数调优



# 查看命令行
- ss -s  Linux使用ss命令查看socket状态

![](https://github.com/wabc1994/WS/blob/master/pic/ss.png)

[Linux使用ss命令查看socket状态](https://blog.51cto.com/215687833/1836119)

- netstat -s| grep LISTEN 主要是查看全连接队列满了之后，服务器端丢弃客户端的syn，查看是否有溢出的SYN，查看服务器accept队列满了之后，客户单有发送过来的ack 确认包被丢弃了


在服务器端进行上万次的tcp连接，我们主要是使用ss系列命令来查看该socket 的具体状态， 在该种情况下面是要比netstat状态命令行要高的情况

 
 
# nagle算法
 
**MTU 数据链路层的最大传输单元**

**需要减去IP数据包包头的大小20Bytes和TCP数据段的包头20Bytes）所以一般MSS值1460 1500字节减去1460字节**


 TCP/IP协议中,无论发送多少数据,总是要在数据前面加上协议头,同时,对方接收到数据,也需要发送ACK表示确认.为了尽可能的利用网络带宽,TCP总是希望尽可能的发送足够大的数据.(在一个连接中会设置MSS参数,因此,TCP/IP希望每次都能够以MSS尺寸的数据块来发送数据).Nagle算法就是为了尽可能发送大块数据,避免网络中充斥着许多小数据块.
        Nagle算法的基本定义是任意时刻,最多只能有一个未被确认的小段. 所谓“小段”,指的是小于MSS尺寸的数据块,所谓“未被确认”,是指一个数据块发送出去后,没有收到对方发送的ACK确认该数据已收到.
        Nagle算法的规则(可参考tcp_output.c文件里tcp_nagle_check函数注释)：
      （1）如果包长度达到MSS,则允许发送；
      （2）如果该包含有FIN,则允许发送；**(要求关闭连接的TCP报文)**
      （3）设置了TCP_NODELAY选项,则允许发送；
      （4）未设置TCP_CORK选项时,若所有发出去的小数据包(包长度小于MSS)均被确认,则允许发送；
      **（5）上述条件都未满足,但发生了超时(一般为200ms),则立即发送.** 每一个数据包的如果超过了200ms,还未被发送出去的话，那么他就有可能


**使用TCP_NODELAY选项可以禁止Negale算法.此时，应用程序向内核递交的每个数据包都会立即发送出去**

Nagle算法主要避免网络因为太多的小包(协议头的比例非常之大)而拥塞

**说白了就是实时性跟网络带宽利用的一个权衡情况**

**Nagle算法只允许一个未被ACK的包存在于网络,它并不管包的大小,因此它事实上就是一个扩展的停-等协议**

# 如果Linux服务器中包含大量一直处于close_wait的tcp连接
两种异常

1. 服务器保持了大量的TIME_WAIT状态。
2. 服务器保持了大量的CLOSE_WAIT状态

**解决问题的总体思路**

优化内核参数在一定程度上能解决time_wait过多的问题，但是应对close_wait还得从应用程序本身出发。

[GitHub出现相同问题too many close_wait](https://github.com/eclipse/jetty.project/issues/1473)

tcp当中是tcp四次挥手被动关闭连接那一方接受到客户端发送过来的FIN后

tcp的挥手连接同样是通过socket建立连接来完成的
 
 ![](https://github.com/wabc1994/WS/commit/4433f7b0dfc4425e50dcda91a84b9664a9c61b06)

1. fin_wait1  发送一个fin 进入 停止等待状态1
2. fin_wait2  接受到服务器端的ack 接受到fin 结束fin_wait2
3. time_wait 接受到 fin 进入，发送ack 时间等待
4. closed    等待两个最长报文生存时间后进入

[tcp 连接的11种状态非常详细](https://liujianguangaaa.iteye.com/blog/975445)

[排除方法一](https://blog.csdn.net/yangguosb/article/details/79095255)

[排除方法二](https://www.jianshu.com/p/394cafc91d18)

被动方关闭
1. 接受到fin后进入close_wait,同时发送一个ack
1. close_wait 发送一个ack 给 
3. 服务器端发送一个fin 进入Last_ACK 状态
>因此从close_wait进入fin的前提条件是被动方没有给主动方发送fin
关于tcp四次挥手详细过程可以看书, 

**tcp的四次挥手会如果不能顺利完成会影响什么资源**
>因为我们知道tcp实质上利用socket 进行通信的，而socket在Linux系统当中是采取一个文件描述符来描述，因此影响的是最终的系统资源，比如导致打开的open files 过多等等情况的


查看一些固定参数可以使用 ulimit -s 或者ulimit -a


## 主动方关闭进入time_wait 可以同过优化内核参数来解决

time_wait的时间为2msl,默认为4min.

优化四次握手主动方的性能请求主要是通过tcp 内核

1. 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭  
net.ipv4.tcp_syncookies = 1  
2. 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭  
net.ipv4.tcp_tw_reuse = 1  
3. 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭  
net.ipv4.tcp_tw_recycle = 1
4. 表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间  
net.ipv4.tcp_fin_timeout=30


## close_wait 是从服务器来解决，也就是我们的应用程序




进入大量的close_wait状态说明套接字是被动关闭了，Server 程序处于CLOSE_WAIT状态，而不是LAST_ACK状态，说明还没有发FIN给主动关闭方。

>我们也都知道Linux系统中分给每个用户的文件句柄数是有限的，而TIME_WAIT和CLOSE_WAIT这两种状态如果一直被保持，那么意味着对应数目的通道(此处应理解为socket，一般一个socket会占用服务器端一个端口，服务器端的端口最大数是65535)一直被占用，一旦达到了上限，则新的请求就无法被处理，接着就是大量Too Many Open Files异常，然后tomcat、nginx、apache崩溃。。






### 危害

1. 由于端口数量限制，同一时间只有有限数量的 socket 连接可以建立。如果太多的 socket 处于 CLOSE_WAIT 状态，一直占用大量端口，将很难再建立新连接。服务器宕机。（每个socket都有一个端口）
2. 占用大量的系统内存，因为内核要为每个socket创建一个socket读缓冲区和发送缓冲区。
>net.ipv4.tcp_rmem=4096 87380 16777216
net.ipv4.tcp_wmem=4096 16384 16777216
3. 如果连接数满了就不能对相应的对段端口创建连接了（实质原因） 



### 原因

**潜在原因分析**

1. 怀疑客户端的 https 连接出现异常后直接退出，没有关闭连接导致。本地修改代码进行模拟测试，没有这个问题
> 当服务器出现大量 CLOSE_WAIT 时，查看客户端的网络状态，有大量的 FIN_WAIT_2，因此客户端已经是正常关闭了连接，问题不在客户单那方面的情况



**什么原因呢**

所以如果将大量CLOSE_WAIT的解决办法总结为一句话那就是：查代码。因为问题出在服务器程序里头啊。

1. 关闭socket不及时：例如I/O线程被意外阻塞，或者I/O线程执行的用户自定义Task比例过高，导致I/O操作处理不及时，链路不能被及时释放。
2. 程序Bug，没有正常发送FIN调用close()，这可能是Netty的Bug，也可能是业务层Bug；

>close_wait 是server端的被动关闭的开始状态，只有调用close后才会转为last_ack，很显然server遗留大量close_wait的描述符，表示均没有调用close。



>程序问题：说的具体一点，服务器端的代码，没有写 close 函数关闭 socket 连接，也就不会发出 FIN 报文段；或者出现死循环，服务器端的代码永远执行不到close()。


**状态变化的情况**

tcp连接从close_wait进入LAST-ACK是服务器端调用代码close(关闭套接字）

>The cause is that your server code is not actively closing client connections by calling close(), leaving sockets in a state known as "half-closed".


### 解决
1. 关闭正在运行的程序，这个需要视业务情况而定。
2. 尽快的修改程序里的bug，然后测试提交到线上服务器。



